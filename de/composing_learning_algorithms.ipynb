{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkdnLiKk71g-"
      },
      "source": [
        "##### Copyright 2022 Die TensorFlow-Autoren."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0asMuNro71hA"
      },
      "outputs": [

      ],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXslvcRocA-0"
      },
      "source": [
        "# Komponieren von Lernalgorithmen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XBJJIqwcXKd"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/federated/tutorials/composing_learning_algorithms\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">VIEN auf TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.by/github/tensorflow/federated/blob/v0.33.0/docs/tutorials/composing_learning_algorithms.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">In Google Colab ausführen</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/federated/blob/v0.3.0/docs/tutorials/composing_learning_algorithms.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Quelle auf GitHub anzeigen</a></td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/federated/docs/tutorials/composing_learning_algorithms.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Notebofrok herunterladen</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnUwFbCAKB2r"
      },
      "source": [
        "## Bevor du anfängst\n",
        "\n",
        "Bevor Sie beginnen, führen Sie bitte Folgendes aus, um sicherzustellen, dass Ihre Umgebung richtig eingerichtet ist. Wenn Sie keine Begrüßung sehen, finden Sie Anweisungen in der [Installationsanleitung](../install.md) . "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrGitA_KnRO0"
      },
      "outputs": [

      ],
      "source": [
        "#@test {\"skip\": true}\n",
        "!pip install --quiet --upgrade tensorflow-federated\n",
        "!pip install --quiet --upgrade nest-asyncio\n",
        "\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGTM6tWOLo8M"
      },
      "outputs": [

      ],
      "source": [
        "from typing import Callable\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yr3ztf28fa1F"
      },
      "source": [
        "**HINWEIS** : Es wurde verifiziert, dass diese Zusammenarbeit mit der [neuesten veröffentlichten Version](https://github.com/tensorflow/federated#compatibility) des pip-Pakets `tensorflow_federated` , aber das Tensorflow Federated-Projekt befindet sich noch in der Entwicklung vor der Veröffentlichung und funktioniert möglicherweise nicht auf `main` ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFlTaHe0jV2S"
      },
      "source": [
        "# Komponieren von Lernalgorithmen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zQlyijofSzI"
      },
      "source": [
        "Das Lernprogramm „ [Building Your Own Federated Learning Algorithm](https://github.com/tensorflow/federated/blob/v0.33.0/docs/tutorials/building_your_own_federated_learning_algorithm.ipynb) “ verwendete den Federated Core von TFF, um direkt eine Version des Federated Averaging (FedAvg)-Algorithmus zu implementieren.\n",
        "\n",
        "In diesem Lernprogramm verwenden Sie föderierte Lernkomponenten in der TFF-API, um föderierte Lernalgorithmen auf modulare Weise zu erstellen, ohne alles von Grund auf neu implementieren zu müssen.\n",
        "\n",
        "Für die Zwecke dieses Lernprogramms implementieren Sie eine Variante von FedAvg, die das Gradienten-Clipping durch lokales Training verwendet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHwcFnLAjqcG"
      },
      "source": [
        "## Lernalgorithmus-Bausteine\n",
        "\n",
        "Auf hoher Ebene können viele Lernalgorithmen in 4 separate Komponenten unterteilt werden, die als **Bausteine** bezeichnet werden. Diese sind wie folgt:\n",
        "\n",
        "1. Distributor (d. h. Server-zu-Client-Kommunikation)\n",
        "2. Client-Arbeit (dh lokale Client-Berechnung)\n",
        "3. Aggregator (d. h. Client-zu-Server-Kommunikation)\n",
        "4. Finalizer (d. h. Serverberechnung mit aggregierten Clientausgaben)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwhOtjlvjboB"
      },
      "source": [
        "Während das [Lernprogramm „Building Your Own Federated Learning Algorithm“](https://github.com/tensorflow/federated/blob/v0.33.0/docs/tutorials/building_your_own_federated_learning_algorithm.ipynb) all diese Bausteine von Grund auf implementiert hat, ist dies oft unnötig. Stattdessen können Sie Bausteine aus ähnlichen Algorithmen wiederverwenden.\n",
        "\n",
        "In diesem Fall müssen Sie zum Implementieren von FedAvg mit Verlaufsbeschneidung nur den **Clientarbeitsbaustein** ändern. Die verbleibenden Blöcke können mit denen identisch sein, die in \"Vanilla\" FedAvg verwendet werden."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMnd0RvGlGjK"
      },
      "source": [
        "# Umsetzung der Kundenarbeit\n",
        "\n",
        "Lassen Sie uns zunächst eine TF-Logik schreiben, die ein lokales Modelltraining mit Gradientenbeschneidung durchführt. Der Einfachheit halber werden Farbverläufe mit einer Norm von höchstens 1 beschnitten."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lqZ-c4MphTU"
      },
      "source": [
        "## TF-Logik"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIw7QQCqltdV"
      },
      "outputs": [

      ],
      "source": [
        "@tf.function\n",
        "def client_update(model: tff.learning.Model,\n",
        "                  dataset: tf.data.Dataset,\n",
        "                  server_weights: tff.learning.ModelWeights,\n",
        "                  client_optimizer: tf.keras.optimizers.Optimizer):\n",
        "  \"\"\"Performs training (using the server model weights) on the client's dataset.\"\"\"\n",
        "  # Initialize the client model with the current server weights.\n",
        "  client_weights = tff.learning.ModelWeights.from_model(model)\n",
        "  tf.nest.map_structure(lambda x, y: x.assign(y),\n",
        "                        client_weights, server_weights)\n",
        "\n",
        "  # Use the client_optimizer to update the local model.\n",
        "  # Keep track of the number of examples as well.\n",
        "  num_examples = 0.0\n",
        "  for batch in dataset:\n",
        "    with tf.GradientTape() as tape:\n",
        "      # Compute a forward pass on the batch of data\n",
        "      outputs = model.forward_pass(batch)\n",
        "      num_examples += tf.cast(outputs.num_examples, tf.float32)\n",
        "\n",
        "    # Compute the corresponding gradient\n",
        "    grads = tape.gradient(outputs.loss, client_weights.trainable)\n",
        "\n",
        "    # Compute the gradient norm and clip\n",
        "    gradient_norm = tf.linalg.global_norm(grads)\n",
        "    if gradient_norm > 1:\n",
        "      grads = tf.nest.map_structure(lambda x: x/gradient_norm, grads)\n",
        "\n",
        "    grads_and_vars = zip(grads, client_weights.trainable)\n",
        "\n",
        "    # Apply the gradient using a client optimizer.\n",
        "    client_optimizer.apply_gradients(grads_and_vars)\n",
        "\n",
        "  # Compute the difference between the server weights and the client weights\n",
        "  client_update = tf.nest.map_structure(tf.subtract,\n",
        "                                        client_weights.trainable,\n",
        "                                        server_weights.trainable)\n",
        "\n",
        "  return tff.learning.templates.ClientResult(\n",
        "      update=client_update, update_weight=num_examples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fe_emK8LpQe0"
      },
      "source": [
        "Es gibt ein paar wichtige Punkte zum obigen Code. Erstens verfolgt es die Anzahl der gesehenen Beispiele, da dies die *Gewichtung* der Client-Aktualisierung darstellt (wenn ein Durchschnitt über Clients berechnet wird).\n",
        "\n",
        "Zweitens verwendet es [`tff.learning.templates.ClientResult`](https://www.tensorflow.org/federated/api_docs/python/tff/learning/templates/ClientResult) , um die Ausgabe zu packen. Dieser Rückgabetyp wird verwendet, um Client-Arbeitsbausteine in `tff.learning` zu standardisieren."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5aKjB1Vpiv3"
      },
      "source": [
        "## Erstellen eines ClientWorkProcess"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IvXUJAzm8ab"
      },
      "source": [
        "Während die obige TF-Logik ein lokales Training mit Clipping durchführt, muss sie dennoch in TFF-Code verpackt werden, um den erforderlichen Baustein zu erstellen.\n",
        "\n",
        "Insbesondere werden die 4 Bausteine als [`tff.templates.MeasuredProcess`](https://www.tensorflow.org/federated/api_docs/python/tff/templates/MeasuredProcess) . Dies bedeutet, dass alle 4 Blöcke sowohl eine `initialize` als auch eine `next` -Funktion haben, die verwendet werden, um die Berechnung zu instanziieren und auszuführen.\n",
        "\n",
        "Dadurch kann jeder Baustein seinen eigenen (auf dem Server gespeicherten) **Zustand** nachverfolgen, wie er für die Durchführung seiner Operationen benötigt wird. Obwohl es in diesem Lernprogramm nicht verwendet wird, kann es für Dinge wie das Verfolgen der Anzahl der aufgetretenen Iterationen oder das Verfolgen von Optimiererzuständen verwendet werden.\n",
        "\n",
        "Clientarbeits-TF-Logik sollte im Allgemeinen als [`tff.learning.templates.ClientWorkProcess`](https://www.tensorflow.org/federated/api_docs/python/tff/learning/templates/ClientWorkProcess) werden, das die erwarteten Typen kodiert, die in das lokale Training des Clients ein- und ausgehen. Es kann wie unten durch ein Modell und einen Optimierer parametrisiert werden."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-I-jPsZmmMy"
      },
      "outputs": [

      ],
      "source": [
        "def build_gradient_clipping_client_work(\n",
        "    model_fn: Callable[[], tff.learning.Model],\n",
        "    optimizer_fn: Callable[[], tf.keras.optimizers.Optimizer],\n",
        ") -> tff.learning.templates.ClientWorkProcess:\n",
        "  \"\"\"Creates a client work process that uses gradient clipping.\"\"\"\n",
        "\n",
        "  with tf.Graph().as_default():\n",
        "    # Wrap model construction in a graph to avoid polluting the global context\n",
        "    # with variables created for this model.\n",
        "    model = model_fn()\n",
        "  data_type = tff.SequenceType(model.input_spec)\n",
        "  model_weights_type = tff.learning.framework.weights_type_from_model(model)\n",
        "\n",
        "  @tff.federated_computation\n",
        "  def initialize_fn():\n",
        "    return tff.federated_value((), tff.SERVER)\n",
        "\n",
        "  @tff.tf_computation(model_weights_type, data_type)\n",
        "  def client_update_computation(model_weights, dataset):\n",
        "    model = model_fn()\n",
        "    optimizer = optimizer_fn()\n",
        "    return client_update(model, dataset, model_weights, optimizer)\n",
        "\n",
        "  @tff.federated_computation(\n",
        "      initialize_fn.type_signature.result,\n",
        "      tff.type_at_clients(model_weights_type),\n",
        "      tff.type_at_clients(data_type)\n",
        "  )\n",
        "  def next_fn(state, model_weights, client_dataset):\n",
        "    client_result = tff.federated_map(\n",
        "        client_update_computation, (model_weights, client_dataset))\n",
        "    # Return empty measurements, though a more complete algorithm might\n",
        "    # measure something here.\n",
        "    measurements = tff.federated_value((), tff.SERVER)\n",
        "    return tff.templates.MeasuredProcessOutput(state, client_result,\n",
        "                                               measurements)\n",
        "  return tff.learning.templates.ClientWorkProcess(\n",
        "      initialize_fn, next_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMUX0d0Sx1Gq"
      },
      "source": [
        "# Erstellen eines Lernalgorithmus\n",
        "\n",
        "Lassen Sie uns die obige Client-Arbeit in einen vollwertigen Algorithmus packen. Zuerst richten wir unsere Daten und unser Modell ein."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQ_N9XbULo8P"
      },
      "source": [
        "## Aufbereitung der Eingabedaten\n",
        "\n",
        "Laden Sie den in TFF enthaltenen EMNIST-Datensatz und verarbeiten Sie ihn vor. Weitere Einzelheiten finden Sie im Lernprogramm zur [Bildklassifizierung](federated_learning_for_image_classification.ipynb) ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-WdnFluLLo8P"
      },
      "outputs": [

      ],
      "source": [
        "emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kq8893GogB8E"
      },
      "source": [
        "Um den Datensatz in unser Modell einzuspeisen, werden die Daten geglättet und in Tupel der Form `(flattened_image_vector, label)` umgewandelt.\n",
        "\n",
        "Wählen wir eine kleine Anzahl von Kunden aus und wenden die obige Vorverarbeitung auf ihre Datensätze an."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Blrh8zJgLo8R"
      },
      "outputs": [

      ],
      "source": [
        "NUM_CLIENTS = 10\n",
        "BATCH_SIZE = 20\n",
        "\n",
        "def preprocess(dataset):\n",
        "\n",
        "  def batch_format_fn(element):\n",
        "    \"\"\"Flatten a batch of EMNIST data and return a (features, label) tuple.\"\"\"\n",
        "    return (tf.reshape(element['pixels'], [-1, 784]), \n",
        "            tf.reshape(element['label'], [-1, 1]))\n",
        "\n",
        "  return dataset.batch(BATCH_SIZE).map(batch_format_fn)\n",
        "\n",
        "client_ids = sorted(emnist_train.client_ids)[:NUM_CLIENTS]\n",
        "federated_train_data = [preprocess(emnist_train.create_tf_dataset_for_client(x))\n",
        "  for x in client_ids\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNO_Y9j_Lo8X"
      },
      "source": [
        "## Vorbereiten des Modells"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJ0I89ixz8yV"
      },
      "source": [
        "Dabei wird dasselbe Modell wie im Lernprogramm zur [Bildklassifizierung](federated_learning_for_image_classification.ipynb) verwendet. Dieses Modell (implementiert über `tf.keras` ) hat eine einzelne verborgene Schicht, gefolgt von einer Softmax-Schicht. Um dieses Modell in TFF zu verwenden, wird das Keras-Modell als [`tff.learning.Model`](https://www.tensorflow.org/federated/api_docs/python/tff/learning/Model) . Dies ermöglicht es uns, den [Vorwärtsdurchgang](https://www.tensorflow.org/federated/api_docs/python/tff/learning/Model#forward_pass) des Modells innerhalb von TFF durchzuführen und [Modellausgaben zu extrahieren](https://www.tensorflow.org/federated/api_docs/python/tff/learning/Model#report_local_unfinalized_metrics) . Weitere Einzelheiten finden Sie auch im Tutorial zur [Bildklassifizierung](federated_learning_for_image_classification.ipynb) ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yfld4oFNLo8Y"
      },
      "outputs": [

      ],
      "source": [
        "def create_keras_model():\n",
        "  initializer = tf.keras.initializers.GlorotNormal(seed=0)\n",
        "  return tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Input(shape=(784,)),\n",
        "      tf.keras.layers.Dense(10, kernel_initializer=initializer),\n",
        "      tf.keras.layers.Softmax(),\n",
        "  ])\n",
        "\n",
        "def model_fn():\n",
        "  keras_model = create_keras_model()\n",
        "  return tff.learning.from_keras_model(\n",
        "      keras_model,\n",
        "      input_spec=federated_train_data[0].element_spec,\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BPxQoGH0bEl"
      },
      "source": [
        "## Vorbereitung der Optimierer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRw9zwdh0dnL"
      },
      "source": [
        "Genau wie in [`tff.learning.algorithms.build_weighted_fed_avg`](https://www.tensorflow.org/federated/api_docs/python/tff/learning/algorithms/build_weighted_fed_avg) gibt es hier zwei Optimierer: einen Client-Optimierer und einen Server-Optimierer. Der Einfachheit halber sind die Optimierer SGD mit unterschiedlichen Lernraten."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOO1ObqJ0cmX"
      },
      "outputs": [

      ],
      "source": [
        "client_optimizer_fn = lambda: tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "server_optimizer_fn = lambda: tf.keras.optimizers.SGD(learning_rate=1.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R64okB7k06sc"
      },
      "source": [
        "## Bausteine definieren\n",
        "\n",
        "Nachdem der Client-Work-Baustein, die Daten, das Modell und die Optimierer eingerichtet sind, müssen noch Bausteine für den Verteiler, den Aggregator und den Finalisierer erstellt werden. Dies kann einfach durch Ausleihen einiger Standardwerte erfolgen, die in TFF verfügbar sind und von FedAvg verwendet werden."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwXOTPeIx2nx"
      },
      "outputs": [

      ],
      "source": [
        "@tff.tf_computation()\n",
        "def initial_model_weights_fn():\n",
        "  return tff.learning.ModelWeights.from_model(model_fn())\n",
        "\n",
        "model_weights_type = initial_model_weights_fn.type_signature.result\n",
        "\n",
        "distributor = tff.learning.templates.build_broadcast_process(model_weights_type)\n",
        "client_work = build_gradient_clipping_client_work(model_fn, client_optimizer_fn)\n",
        "\n",
        "# TFF aggregators use a factory pattern, which create an aggregator\n",
        "# based on the output type of the client work. This also uses a float (the number\n",
        "# of examples) to govern the weight in the average being computed.)\n",
        "aggregator_factory = tff.aggregators.MeanFactory()\n",
        "aggregator = aggregator_factory.create(model_weights_type.trainable,\n",
        "                                       tff.TensorType(tf.float32))\n",
        "finalizer = tff.learning.templates.build_apply_optimizer_finalizer(\n",
        "    server_optimizer_fn, model_weights_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEYYNHqI1Jif"
      },
      "source": [
        "## Zusammenstellen der Bausteine\n",
        "\n",
        "Schließlich können Sie einen eingebauten **Composer** in TFF verwenden, um die Bausteine zusammenzusetzen. Dies ist ein relativ einfacher Composer, der die 4 oben genannten Bausteine nimmt und ihre Typen miteinander verbindet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_86iNeM0IBm"
      },
      "outputs": [

      ],
      "source": [
        "fed_avg_with_clipping = tff.learning.templates.compose_learning_process(\n",
        "    initial_model_weights_fn,\n",
        "    distributor,\n",
        "    client_work,\n",
        "    aggregator,\n",
        "    finalizer\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcK69pCG16-E"
      },
      "source": [
        "# Ausführen des Algorithmus\n",
        "\n",
        "Nun, da der Algorithmus fertig ist, lassen Sie ihn ausführen. **Initialisieren Sie zunächst** den Algorithmus. Der **Zustand** dieses Algorithmus hat eine Komponente für jeden Baustein, zusammen mit einer für die *globalen Modellgewichte* ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jg22oFx11YKK"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "()"
            ]
          },
          "execution_count": 26,
          "metadata": {
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "state = fed_avg_with_clipping.initialize()\n",
        "\n",
        "state.client_work"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmCiEdoq2doJ"
      },
      "source": [
        "Wie erwartet hat die Client-Arbeit einen leeren Zustand (denken Sie an den Client-Arbeitscode oben!). Andere Bausteine können jedoch einen nicht leeren Zustand haben. Beispielsweise verfolgt der Finalizer, wie viele Iterationen stattgefunden haben. Da `next` noch nicht ausgeführt wurde, hat es den Status `0` ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEuB-8Z71-bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0]"
            ]
          },
          "execution_count": 27,
          "metadata": {
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "state.finalizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2N9XObhZ2zSQ"
      },
      "source": [
        "Führen Sie nun eine Trainingsrunde durch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKhPuBgW1-3c"
      },
      "outputs": [

      ],
      "source": [
        "learning_process_output = fed_avg_with_clipping.next(state, federated_train_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7L0jKEe29bk"
      },
      "source": [
        "Die Ausgabe davon ( `tff.learning.templates.LearningProcessOutput` ) hat sowohl eine `.state` als auch eine `.metrics` Ausgabe. Schauen wir uns beide an."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMsBmmQz28AZ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1]"
            ]
          },
          "execution_count": 29,
          "metadata": {
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "learning_process_output.state.finalizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwcfhAbP3VkH"
      },
      "source": [
        "Der Finalizer-Zustand hat sich eindeutig um eins erhöht, da eine Runde von `.next` ausgeführt wurde."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0K91G_Ob3E05"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('distributor', ()),\n",
              "             ('client_work', ()),\n",
              "             ('aggregator',\n",
              "              OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "             ('finalizer', ())])"
            ]
          },
          "execution_count": 30,
          "metadata": {
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "learning_process_output.metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sDyO9uz3Jaz"
      },
      "source": [
        "Während die Metriken leer sind, sind sie für komplexere und praktischere Algorithmen im Allgemeinen voller nützlicher Informationen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPpxe7Ie3gLJ"
      },
      "source": [
        "# Fazit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8uEZw-T3iBB"
      },
      "source": [
        "Indem Sie das obige Baustein-/Composer-Framework verwenden, können Sie völlig neue Lernalgorithmen erstellen, ohne alles von Grund auf neu machen zu müssen. Dies ist jedoch nur der Ausgangspunkt. Dieses Framework macht es viel einfacher, Algorithmen als einfache Modifikationen von FedAvg auszudrücken. Weitere Algorithmen finden Sie unter [`tff.learning.algorithms`](https://www.tensorflow.org/federated/api_docs/python/tff/learning/algorithms) , das Algorithmen wie [FedProx](https://www.tensorflow.org/federated/api_docs/python/tff/learning/algorithms/build_weighted_fed_prox) und [FedAvg mit Client-Lernratenplanung](https://www.tensorflow.org/federated/api_docs/python/tff/learning/algorithms/build_weighted_fed_avg_with_optimizer_schedule) enthält. Diese APIs können sogar die Implementierung völlig neuer Algorithmen unterstützen, z. B. [föderiertes k-Means-Clustering](https://www.tensorflow.org/federated/api_docs/python/tff/learning/algorithms/build_fed_kmeans) ."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [

      ],
      "name": "composing_learning_algorithms.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
