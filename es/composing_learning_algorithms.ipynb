{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkdnLiKk71g-"
      },
      "source": [
        "##### Copyright 2022 Los autores de TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0asMuNro71hA"
      },
      "outputs": [

      ],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXslvcRocA-0"
      },
      "source": [
        "# Composición de algoritmos de aprendizaje"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XBJJIqwcXKd"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/federated/tutorials/composing_learning_algorithms\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">VIEN en TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.by/github/tensorflow/federated/blob/v0.33.0/docs/tutorials/composing_learning_algorithms.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/federated/blob/v0.33.0/docs/tutorials/composing_learning_algorithms.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fuente en GitHub</a></td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/federated/docs/tutorials/composing_learning_algorithms.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar libreta</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnUwFbCAKB2r"
      },
      "source": [
        "## Antes de que empieces\n",
        "\n",
        "Antes de comenzar, ejecute lo siguiente para asegurarse de que su entorno esté configurado correctamente. Si no ve un saludo, consulte la guía de [instalación](../install.md) para obtener instrucciones. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrGitA_KnRO0"
      },
      "outputs": [

      ],
      "source": [
        "#@test {\"skip\": true}\n",
        "!pip install --quiet --upgrade tensorflow-federated\n",
        "!pip install --quiet --upgrade nest-asyncio\n",
        "\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGTM6tWOLo8M"
      },
      "outputs": [

      ],
      "source": [
        "from typing import Callable\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yr3ztf28fa1F"
      },
      "source": [
        "**NOTA** : Se ha verificado que esta colaboración funciona con la [última versión lanzada](https://github.com/tensorflow/federated#compatibility) del paquete pip `tensorflow_federated` , pero el proyecto Tensorflow Federated todavía está en desarrollo preliminar y es posible que no funcione en `main` ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFlTaHe0jV2S"
      },
      "source": [
        "# Composición de algoritmos de aprendizaje"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zQlyijofSzI"
      },
      "source": [
        "El tutorial Cómo crear [su propio algoritmo de aprendizaje](https://github.com/tensorflow/federated/blob/v0.33.0/docs/tutorials/building_your_own_federated_learning_algorithm.ipynb) federado utilizó el núcleo federado de TFF para implementar directamente una versión del algoritmo de promedio federado (FedAvg).\n",
        "\n",
        "En este tutorial, utilizará componentes de aprendizaje federado en la API de TFF para crear algoritmos de aprendizaje federado de manera modular, sin tener que volver a implementar todo desde cero.\n",
        "\n",
        "A los efectos de este tutorial, implementará una variante de FedAvg que emplea el recorte de gradiente a través del entrenamiento local."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHwcFnLAjqcG"
      },
      "source": [
        "## Bloques de construcción de algoritmos de aprendizaje\n",
        "\n",
        "En un nivel alto, muchos algoritmos de aprendizaje se pueden separar en 4 componentes separados, denominados **bloques de construcción** . Estos son los siguientes:\n",
        "\n",
        "1. Distribuidor (es decir, comunicación de servidor a cliente)\n",
        "2. Trabajo del cliente (es decir, cálculo del cliente local)\n",
        "3. Agregador (es decir, comunicación de cliente a servidor)\n",
        "4. Finalizador (es decir, cómputo del servidor utilizando salidas de cliente agregadas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwhOtjlvjboB"
      },
      "source": [
        "Si bien el [tutorial Construir su propio algoritmo de aprendizaje federado](https://github.com/tensorflow/federated/blob/v0.33.0/docs/tutorials/building_your_own_federated_learning_algorithm.ipynb) implementó todos estos componentes básicos desde cero, esto a menudo es innecesario. En su lugar, puede reutilizar bloques de construcción de algoritmos similares.\n",
        "\n",
        "En este caso, para implementar FedAvg con recorte de degradado, solo necesita modificar el componente básico del **trabajo del cliente** . Los bloques restantes pueden ser idénticos a los que se utilizan en FedAvg \"vainilla\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMnd0RvGlGjK"
      },
      "source": [
        "# Implementación del trabajo del cliente\n",
        "\n",
        "Primero, escribamos la lógica TF que realiza el entrenamiento del modelo local con recorte de gradiente. Para simplificar, los gradientes se recortarán con la norma como máximo 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lqZ-c4MphTU"
      },
      "source": [
        "## Lógica TF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIw7QQCqltdV"
      },
      "outputs": [

      ],
      "source": [
        "@tf.function\n",
        "def client_update(model: tff.learning.Model,\n",
        "                  dataset: tf.data.Dataset,\n",
        "                  server_weights: tff.learning.ModelWeights,\n",
        "                  client_optimizer: tf.keras.optimizers.Optimizer):\n",
        "  \"\"\"Performs training (using the server model weights) on the client's dataset.\"\"\"\n",
        "  # Initialize the client model with the current server weights.\n",
        "  client_weights = tff.learning.ModelWeights.from_model(model)\n",
        "  tf.nest.map_structure(lambda x, y: x.assign(y),\n",
        "                        client_weights, server_weights)\n",
        "\n",
        "  # Use the client_optimizer to update the local model.\n",
        "  # Keep track of the number of examples as well.\n",
        "  num_examples = 0.0\n",
        "  for batch in dataset:\n",
        "    with tf.GradientTape() as tape:\n",
        "      # Compute a forward pass on the batch of data\n",
        "      outputs = model.forward_pass(batch)\n",
        "      num_examples += tf.cast(outputs.num_examples, tf.float32)\n",
        "\n",
        "    # Compute the corresponding gradient\n",
        "    grads = tape.gradient(outputs.loss, client_weights.trainable)\n",
        "\n",
        "    # Compute the gradient norm and clip\n",
        "    gradient_norm = tf.linalg.global_norm(grads)\n",
        "    if gradient_norm > 1:\n",
        "      grads = tf.nest.map_structure(lambda x: x/gradient_norm, grads)\n",
        "\n",
        "    grads_and_vars = zip(grads, client_weights.trainable)\n",
        "\n",
        "    # Apply the gradient using a client optimizer.\n",
        "    client_optimizer.apply_gradients(grads_and_vars)\n",
        "\n",
        "  # Compute the difference between the server weights and the client weights\n",
        "  client_update = tf.nest.map_structure(tf.subtract,\n",
        "                                        client_weights.trainable,\n",
        "                                        server_weights.trainable)\n",
        "\n",
        "  return tff.learning.templates.ClientResult(\n",
        "      update=client_update, update_weight=num_examples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fe_emK8LpQe0"
      },
      "source": [
        "Hay algunos puntos importantes sobre el código anterior. Primero, realiza un seguimiento de la cantidad de ejemplos vistos, ya que esto constituirá el *peso* de la actualización del cliente (al calcular un promedio entre los clientes).\n",
        "\n",
        "En segundo lugar, utiliza [`tff.learning.templates.ClientResult`](https://www.tensorflow.org/federated/api_docs/python/tff/learning/templates/ClientResult) para empaquetar la salida. Este tipo de devolución se utiliza para estandarizar los componentes básicos del trabajo del cliente en `tff.learning` ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5aKjB1Vpiv3"
      },
      "source": [
        "## Creación de un ClientWorkProcess"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IvXUJAzm8ab"
      },
      "source": [
        "Si bien la lógica TF anterior realizará un entrenamiento local con recorte, aún debe envolverse en el código TFF para crear el bloque de construcción necesario.\n",
        "\n",
        "Específicamente, los 4 bloques de construcción se representan como [`tff.templates.MeasuredProcess`](https://www.tensorflow.org/federated/api_docs/python/tff/templates/MeasuredProcess) . Esto significa que los 4 bloques tienen una función de `initialize` y `next` que se usa para instanciar y ejecutar el cálculo.\n",
        "\n",
        "Esto permite que cada bloque de construcción realice un seguimiento de su propio **estado** (almacenado en el servidor) según sea necesario para realizar sus operaciones. Si bien no se usará en este tutorial, se puede usar para cosas como el seguimiento de cuántas iteraciones se han producido o el seguimiento de los estados del optimizador.\n",
        "\n",
        "La lógica de TF del trabajo del cliente generalmente debe envolverse como [`tff.learning.templates.ClientWorkProcess`](https://www.tensorflow.org/federated/api_docs/python/tff/learning/templates/ClientWorkProcess) , que codifica los tipos esperados que entran y salen de la capacitación local del cliente. Puede ser parametrizado por un modelo y optimizador, como se muestra a continuación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-I-jPsZmmMy"
      },
      "outputs": [

      ],
      "source": [
        "def build_gradient_clipping_client_work(\n",
        "    model_fn: Callable[[], tff.learning.Model],\n",
        "    optimizer_fn: Callable[[], tf.keras.optimizers.Optimizer],\n",
        ") -> tff.learning.templates.ClientWorkProcess:\n",
        "  \"\"\"Creates a client work process that uses gradient clipping.\"\"\"\n",
        "\n",
        "  with tf.Graph().as_default():\n",
        "    # Wrap model construction in a graph to avoid polluting the global context\n",
        "    # with variables created for this model.\n",
        "    model = model_fn()\n",
        "  data_type = tff.SequenceType(model.input_spec)\n",
        "  model_weights_type = tff.learning.framework.weights_type_from_model(model)\n",
        "\n",
        "  @tff.federated_computation\n",
        "  def initialize_fn():\n",
        "    return tff.federated_value((), tff.SERVER)\n",
        "\n",
        "  @tff.tf_computation(model_weights_type, data_type)\n",
        "  def client_update_computation(model_weights, dataset):\n",
        "    model = model_fn()\n",
        "    optimizer = optimizer_fn()\n",
        "    return client_update(model, dataset, model_weights, optimizer)\n",
        "\n",
        "  @tff.federated_computation(\n",
        "      initialize_fn.type_signature.result,\n",
        "      tff.type_at_clients(model_weights_type),\n",
        "      tff.type_at_clients(data_type)\n",
        "  )\n",
        "  def next_fn(state, model_weights, client_dataset):\n",
        "    client_result = tff.federated_map(\n",
        "        client_update_computation, (model_weights, client_dataset))\n",
        "    # Return empty measurements, though a more complete algorithm might\n",
        "    # measure something here.\n",
        "    measurements = tff.federated_value((), tff.SERVER)\n",
        "    return tff.templates.MeasuredProcessOutput(state, client_result,\n",
        "                                               measurements)\n",
        "  return tff.learning.templates.ClientWorkProcess(\n",
        "      initialize_fn, next_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMUX0d0Sx1Gq"
      },
      "source": [
        "# Componer un algoritmo de aprendizaje\n",
        "\n",
        "Pongamos el trabajo del cliente anterior en un algoritmo completo. Primero, configuremos nuestros datos y modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQ_N9XbULo8P"
      },
      "source": [
        "## Preparación de los datos de entrada\n",
        "\n",
        "Cargue y preprocese el conjunto de datos EMNIST incluido en TFF. Para obtener más detalles, consulte el tutorial de [clasificación de imágenes](federated_learning_for_image_classification.ipynb) ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-WdnFluLLo8P"
      },
      "outputs": [

      ],
      "source": [
        "emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kq8893GogB8E"
      },
      "source": [
        "Para introducir el conjunto de datos en nuestro modelo, los datos se aplanan y se convierten en tuplas de la forma `(flattened_image_vector, label)` .\n",
        "\n",
        "Seleccionemos una pequeña cantidad de clientes y apliquemos el preprocesamiento anterior a sus conjuntos de datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Blrh8zJgLo8R"
      },
      "outputs": [

      ],
      "source": [
        "NUM_CLIENTS = 10\n",
        "BATCH_SIZE = 20\n",
        "\n",
        "def preprocess(dataset):\n",
        "\n",
        "  def batch_format_fn(element):\n",
        "    \"\"\"Flatten a batch of EMNIST data and return a (features, label) tuple.\"\"\"\n",
        "    return (tf.reshape(element['pixels'], [-1, 784]), \n",
        "            tf.reshape(element['label'], [-1, 1]))\n",
        "\n",
        "  return dataset.batch(BATCH_SIZE).map(batch_format_fn)\n",
        "\n",
        "client_ids = sorted(emnist_train.client_ids)[:NUM_CLIENTS]\n",
        "federated_train_data = [preprocess(emnist_train.create_tf_dataset_for_client(x))\n",
        "  for x in client_ids\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNO_Y9j_Lo8X"
      },
      "source": [
        "## Preparando el modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJ0I89ixz8yV"
      },
      "source": [
        "Esto utiliza el mismo modelo que en el tutorial de [clasificación de imágenes](federated_learning_for_image_classification.ipynb) . Este modelo (implementado a través `tf.keras` ) tiene una sola capa oculta, seguida de una capa softmax. Para usar este modelo en TFF, el modelo de Keras se envuelve como [`tff.learning.Model`](https://www.tensorflow.org/federated/api_docs/python/tff/learning/Model) . Esto nos permite realizar el [pase hacia adelante](https://www.tensorflow.org/federated/api_docs/python/tff/learning/Model#forward_pass) del modelo dentro de TFF y [extraer los resultados del modelo](https://www.tensorflow.org/federated/api_docs/python/tff/learning/Model#report_local_unfinalized_metrics) . Para obtener más detalles, consulte también el tutorial de [clasificación de imágenes](federated_learning_for_image_classification.ipynb) ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yfld4oFNLo8Y"
      },
      "outputs": [

      ],
      "source": [
        "def create_keras_model():\n",
        "  initializer = tf.keras.initializers.GlorotNormal(seed=0)\n",
        "  return tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Input(shape=(784,)),\n",
        "      tf.keras.layers.Dense(10, kernel_initializer=initializer),\n",
        "      tf.keras.layers.Softmax(),\n",
        "  ])\n",
        "\n",
        "def model_fn():\n",
        "  keras_model = create_keras_model()\n",
        "  return tff.learning.from_keras_model(\n",
        "      keras_model,\n",
        "      input_spec=federated_train_data[0].element_spec,\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BPxQoGH0bEl"
      },
      "source": [
        "## Preparando los optimizadores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRw9zwdh0dnL"
      },
      "source": [
        "Al igual que en [`tff.learning.algorithms.build_weighted_fed_avg`](https://www.tensorflow.org/federated/api_docs/python/tff/learning/algorithms/build_weighted_fed_avg) , aquí hay dos optimizadores: un optimizador de cliente y un optimizador de servidor. Para simplificar, los optimizadores serán SGD con diferentes tasas de aprendizaje."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOO1ObqJ0cmX"
      },
      "outputs": [

      ],
      "source": [
        "client_optimizer_fn = lambda: tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "server_optimizer_fn = lambda: tf.keras.optimizers.SGD(learning_rate=1.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R64okB7k06sc"
      },
      "source": [
        "## Definición de los bloques de construcción\n",
        "\n",
        "Ahora que el bloque de construcción del trabajo del cliente, los datos, el modelo y los optimizadores están configurados, queda por crear los bloques de construcción para el distribuidor, el agregador y el finalizador. Esto se puede hacer simplemente tomando prestados algunos valores predeterminados disponibles en TFF y que son utilizados por FedAvg."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwXOTPeIx2nx"
      },
      "outputs": [

      ],
      "source": [
        "@tff.tf_computation()\n",
        "def initial_model_weights_fn():\n",
        "  return tff.learning.ModelWeights.from_model(model_fn())\n",
        "\n",
        "model_weights_type = initial_model_weights_fn.type_signature.result\n",
        "\n",
        "distributor = tff.learning.templates.build_broadcast_process(model_weights_type)\n",
        "client_work = build_gradient_clipping_client_work(model_fn, client_optimizer_fn)\n",
        "\n",
        "# TFF aggregators use a factory pattern, which create an aggregator\n",
        "# based on the output type of the client work. This also uses a float (the number\n",
        "# of examples) to govern the weight in the average being computed.)\n",
        "aggregator_factory = tff.aggregators.MeanFactory()\n",
        "aggregator = aggregator_factory.create(model_weights_type.trainable,\n",
        "                                       tff.TensorType(tf.float32))\n",
        "finalizer = tff.learning.templates.build_apply_optimizer_finalizer(\n",
        "    server_optimizer_fn, model_weights_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEYYNHqI1Jif"
      },
      "source": [
        "## Componer los bloques de construcción\n",
        "\n",
        "Finalmente, puede usar un **compositor** incorporado en TFF para unir los componentes básicos. Este es un compositor relativamente simple, que toma los 4 bloques de construcción anteriores y conecta sus tipos juntos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_86iNeM0IBm"
      },
      "outputs": [

      ],
      "source": [
        "fed_avg_with_clipping = tff.learning.templates.compose_learning_process(\n",
        "    initial_model_weights_fn,\n",
        "    distributor,\n",
        "    client_work,\n",
        "    aggregator,\n",
        "    finalizer\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcK69pCG16-E"
      },
      "source": [
        "# Ejecutando el algoritmo\n",
        "\n",
        "Ahora que el algoritmo está listo, vamos a ejecutarlo. Primero, **inicialice** el algoritmo. El **estado** de este algoritmo tiene un componente para cada bloque de construcción, junto con uno para los *pesos del modelo global* ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jg22oFx11YKK"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "()"
            ]
          },
          "execution_count": 26,
          "metadata": {
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "state = fed_avg_with_clipping.initialize()\n",
        "\n",
        "state.client_work"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmCiEdoq2doJ"
      },
      "source": [
        "Como era de esperar, el trabajo del cliente tiene un estado vacío (¡recuerde el código de trabajo del cliente anterior!). Sin embargo, otros bloques de construcción pueden tener un estado no vacío. Por ejemplo, el finalizador realiza un seguimiento de cuántas iteraciones se han producido. Dado que `next` aún no se ha ejecutado, tiene un estado de `0` ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEuB-8Z71-bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0]"
            ]
          },
          "execution_count": 27,
          "metadata": {
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "state.finalizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2N9XObhZ2zSQ"
      },
      "source": [
        "Ahora ejecuta una ronda de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKhPuBgW1-3c"
      },
      "outputs": [

      ],
      "source": [
        "learning_process_output = fed_avg_with_clipping.next(state, federated_train_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7L0jKEe29bk"
      },
      "source": [
        "La salida de esto ( `tff.learning.templates.LearningProcessOutput` ) tiene una salida `.state` y `.metrics` . Veamos ambos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMsBmmQz28AZ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1]"
            ]
          },
          "execution_count": 29,
          "metadata": {
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "learning_process_output.state.finalizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwcfhAbP3VkH"
      },
      "source": [
        "Claramente, el estado del finalizador se ha incrementado en uno, ya que se ha ejecutado una ronda de `.next` ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0K91G_Ob3E05"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('distributor', ()),\n",
              "             ('client_work', ()),\n",
              "             ('aggregator',\n",
              "              OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "             ('finalizer', ())])"
            ]
          },
          "execution_count": 30,
          "metadata": {
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "learning_process_output.metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sDyO9uz3Jaz"
      },
      "source": [
        "Si bien las métricas están vacías, para algoritmos más complejos y prácticos generalmente estarán llenas de información útil."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPpxe7Ie3gLJ"
      },
      "source": [
        "# Conclusión"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8uEZw-T3iBB"
      },
      "source": [
        "Al utilizar el marco de creación de bloques/compositores anterior, puede crear algoritmos de aprendizaje completamente nuevos, sin tener que volver a hacer todo desde cero. Sin embargo, este es sólo el punto de partida. Este marco hace que sea mucho más fácil expresar algoritmos como simples modificaciones de FedAvg. Para obtener más algoritmos, consulte [`tff.learning.algorithms`](https://www.tensorflow.org/federated/api_docs/python/tff/learning/algorithms) , que contiene algoritmos como [FedProx](https://www.tensorflow.org/federated/api_docs/python/tff/learning/algorithms/build_weighted_fed_prox) y [FedAvg con programación de tasa de aprendizaje del cliente](https://www.tensorflow.org/federated/api_docs/python/tff/learning/algorithms/build_weighted_fed_avg_with_optimizer_schedule) . Estas API pueden incluso ayudar a implementaciones de algoritmos completamente nuevos, como [el agrupamiento federado de k-means](https://www.tensorflow.org/federated/api_docs/python/tff/learning/algorithms/build_fed_kmeans) ."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [

      ],
      "name": "composing_learning_algorithms.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
